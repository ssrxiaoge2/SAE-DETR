__include__: [
  '../dfine/dfine_hgnetv2_s_custom.yml',
  '../dataset/custom_detection.yml',
  '../base/deim.yml'
]
checkpoint_freq: 400
print_freq: 100
output_dir: ./outputs/deim_hgnetv2_s_custom

DEIM:
  backbone: HGNetv2_PSConv
  encoder: HybridEncoder_C2f_FiGCA

HGNetv2_PSConv:
  name: 'B0'
  return_idx: [1, 2, 3]
  freeze_at: -1
  freeze_norm: False
  use_lab: True
  pretrained: False
  
DFINETransformer:
  num_layers: 3  # 4 5 6
  eval_idx: -1  # -2 -3 -4

HybridEncoder_C2f_FiGCA:
  in_channels: [256, 512, 1024]
  hidden_dim: 256
  depth_mult: 0.34
  expansion: 0.5

optimizer:
  type: AdamW
  params: 
    - 
      params: '^(?=.*backbone)(?!.*bn).*$'
      lr: 0.0001
    - 
      params: '^(?=.*(?:norm|bn)).*$'     # except bias
      weight_decay: 0.

  lr: 0.0001
  betas: [0.9, 0.999]
  weight_decay: 0.0001


# Increase to search for the optimal ema
epoches: 300 # 120 + 4n

## Our LR-Scheduler
flat_epoch: 148    # 4 + epoch // 2, e.g., 40 = 4 + 72 / 2
no_aug_epoch: 12

## Our DataAug
train_dataloader: 
  dataset: 
    transforms:
      policy:
        epoch: [4, 148, 288]   # list 

  collate_fn:
    mixup_epochs: [4, 148]
    stop_epoch: 288
  total_batch_size: 4
val_dataloader:
  total_batch_size: 4